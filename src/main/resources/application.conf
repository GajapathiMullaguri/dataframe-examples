conf {

    s3_conf {
        access_key = "AKIA53CFDSYPK6AISFRH"
        secret_access_key = "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"
        s3_bucket = "awssparkscala"
    }

    mysql_conf {
        hostname = "test.ccedcfxrbeo1.ap-south-1.rds.amazonaws.com"
        port = "3306"
        database = "testdb"
        username = "master"
        password = "Temp1234"
    }

    sftp_conf {
        hostname = "ec2-34-241-44-197.eu-west-1.compute.amazonaws.com"
        port = "22"
        username = "ubuntu"
        pem = "src\\main\\resources\\test.ppk"
        filetype = "csv"
        delimiter = "|"
        directory = "/home/ubuntu/data"
    }

    mongodb_config {
        input.uri = "mongodb://13.234.48.111"
        output.uri = "mongodb://13.234.48.111"
        input.database = "school"
        database = "school"
        collection = "students"
    }

    redshift_conf = {
        host = "redshift-spark.cg0sqvcxh0rr.eu-west-1.redshift.amazonaws.com"
        port = "5439"
        database = "dev"
        username = "master"
        password = "Test1234"
        filetype = "csv"
        delimiter = "|"
    }

    spark_sql_demo = {
        agg_demo = """
            select
                AccountNumber,
                UniqueTransactionDescriptions,
                sort_array(UniqueTransactionDescriptions, false) as OrderedUniqueTransactionDescriptions,
                size(UniqueTransactionDescriptions) as CountOfUniqueTransactionTypes,
                array_contains(UniqueTransactionDescriptions, 'Movies') as WentToMovies
            from
                agg_finances
            """

        case_when_demo = """
            select
                company,
                employee.firstName as firstName,
                case
                    when company = 'FamilyCo' then 'Premium'
                    when company = 'OldCo' then 'Legacy'
                    else 'Standard'
                end as Tier
            from
                employees
            """

    }
}